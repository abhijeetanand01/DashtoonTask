{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc882dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import mse_loss\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torchvision.models.feature_extraction import create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc4fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_style = 10\n",
    "NUM_STYLE = 10\n",
    "\n",
    "MEAN = (0.485, 0.456, 0.406)\n",
    "STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "normalize = transforms.Normalize(mean=MEAN, std=STD)\n",
    "denormalize = transforms.Normalize(mean=[-m/s for m, s in zip(MEAN, STD)],\n",
    "                          std=[1/std for std in STD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68ba502",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_path = '../Dashtoon Task/MSGNet/data/artist/'\n",
    "content_path = '../Dashtoon Task/AdaIn/dataset/content/train_2.5k'\n",
    "\n",
    "\n",
    "style_index = -1\n",
    "batch_size = 2\n",
    "lr = 1e-4\n",
    "style_weight = 5.0\n",
    "iterations = 40000\n",
    "tv_weight = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386de397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(imsize = None, cropsize = None, cencrop = False):\n",
    "    transformer = []\n",
    "    if imsize:\n",
    "        transformer.append(transforms.Resize(imsize))\n",
    "    if cropsize:\n",
    "        if cencrop:\n",
    "            transformer.append(transforms.CenterCrop(cropsize))\n",
    "        else:\n",
    "            transformer.append(transforms.RandomCrop(cropsize))\n",
    "    \n",
    "    transformer.append(transforms.ToTensor())\n",
    "    transformer.append(normalize)\n",
    "    return transforms.Compose(transformer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f75626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset:\n",
    "    def __init__(self, dir_path):\n",
    "        self.images = sorted(list(dir_path.glob('*.jpg')))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.images[index]).convert('RGB')\n",
    "        return img, index\n",
    "    \n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, imsize = 256, cropsize = 240, cencrop = False):\n",
    "        self.transforms = get_transforms(imsize=imsize, cropsize = cropsize, cencrop = cencrop)\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        images, indices = list(zip(*batch))\n",
    "        inputs = torch.stack(tuple(self.transforms(image) for image in images))\n",
    "        return inputs, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b1dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_nodes = ['relu_3_3']\n",
    "style_nodes = ['relu_1_2', 'relu_2_2', 'relu_3_3', 'relu_4_2']\n",
    "return_nodes = {3: 'relu_1_2',\n",
    "                    8: 'relu_2_2',\n",
    "                    15: 'relu_3_3',\n",
    "                    22: 'relu_4_2'}\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ca4f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dataset = ImageDataset(dir_path = Path(content_path))\n",
    "style_dataset = ImageDataset(dir_path = Path(style_path))\n",
    "\n",
    "data_processor = DataProcessor(imsize=256, cropsize=240, cencrop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c048e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dataloader = DataLoader(dataset=content_dataset, \n",
    "                                batch_size = batch_size, \n",
    "                                shuffle = True, \n",
    "                                collate_fn = data_processor)\n",
    "\n",
    "\n",
    "style_dataloader = DataLoader(dataset=style_dataset, \n",
    "                                batch_size = batch_size, \n",
    "                                shuffle = True, \n",
    "                                collate_fn = data_processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f6093ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92850861",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da310a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_network = create_feature_extractor(vgg, return_nodes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0290be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIN(nn.Module):\n",
    "    def __init__(self, num_style, ch):\n",
    "        super(CIN, self).__init__()\n",
    "        self.normalize = nn.InstanceNorm2d(ch, affine=False)\n",
    "        self.offset = nn.Parameter(0.01 * torch.randn(1, num_style, ch))\n",
    "        self.scale = nn.Parameter(1 + 0.01 * torch.randn(1, num_style, ch))\n",
    "\n",
    "    def forward(self, x, style_codes):\n",
    "        b, c, h, w = x.size()\n",
    "\n",
    "        x = self.normalize(x)\n",
    "\n",
    "        gamma = torch.sum(self.scale * style_codes, dim=1).view(b, c, 1, 1)\n",
    "        beta = torch.sum(self.offset * style_codes, dim=1).view(b, c, 1, 1)\n",
    "\n",
    "        x = x * gamma + beta\n",
    "\n",
    "        return x.view(b, c, h, w)\n",
    "\n",
    "\n",
    "class ConvWithCIN(nn.Module):\n",
    "    def __init__(self, num_style, in_ch, out_ch, stride, activation, ksize):\n",
    "        super(ConvWithCIN, self).__init__()\n",
    "        self.padding = nn.ReflectionPad2d(ksize // 2)\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, ksize, stride)\n",
    "\n",
    "        self.cin = CIN(num_style, out_ch)\n",
    "\n",
    "        if activation == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "\n",
    "        elif activation == \"linear\":\n",
    "            self.activation = lambda x: x\n",
    "\n",
    "    def forward(self, x, style_codes):\n",
    "        x = self.padding(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.cin(x, style_codes)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_style, in_ch, out_ch):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = ConvWithCIN(num_style, in_ch, out_ch, 1, \"relu\", 3)\n",
    "        self.conv2 = ConvWithCIN(num_style, out_ch, out_ch, 1, \"linear\", 3)\n",
    "\n",
    "    def forward(self, x, style_codes):\n",
    "        out = self.conv1(x, style_codes)\n",
    "        out = self.conv2(out, style_codes)\n",
    "\n",
    "        return x + out\n",
    "\n",
    "\n",
    "class UpsamleBlock(nn.Module):\n",
    "    def __init__(self, num_style, in_ch, out_ch):\n",
    "        super(UpsamleBlock, self).__init__()\n",
    "        self.conv = ConvWithCIN(num_style, in_ch, out_ch, 1, \"relu\", 3)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x, style_codes):\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv(x, style_codes)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class StyleTransferNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, num_style=10):\n",
    "        super(StyleTransferNetwork, self).__init__()\n",
    "        self.conv1 = ConvWithCIN(num_style,  3, 32, 1, 'relu', 9)\n",
    "        self.conv2 = ConvWithCIN(num_style, 32, 64, 2, 'relu', 3)\n",
    "        self.conv3 = ConvWithCIN(num_style, 64, 128, 2, 'relu', 3)\n",
    "\n",
    "        self.residual1 = ResidualBlock(num_style, 128, 128)\n",
    "#         self.residual2 = ResidualBlock(num_style, 128, 128)\n",
    "        self.residual3 = ResidualBlock(num_style, 128, 128)\n",
    "#         self.residual4 = ResidualBlock(num_style, 128, 128)\n",
    "        self.residual5 = ResidualBlock(num_style, 128, 128)\n",
    "\n",
    "        self.upsampling1 = UpsamleBlock(num_style, 128, 64)\n",
    "        self.upsampling2 = UpsamleBlock(num_style, 64, 32)\n",
    "\n",
    "        self.conv4 = ConvWithCIN(num_style, 32, 3, 1, 'linear', 9)\n",
    "\n",
    "    def forward(self, x, style_codes):\n",
    "        x = self.conv1(x, style_codes)\n",
    "        x = self.conv2(x, style_codes)\n",
    "        x = self.conv3(x, style_codes)\n",
    "\n",
    "        x = self.residual1(x, style_codes)\n",
    "#         x = self.residual2(x, style_codes)\n",
    "        x = self.residual3(x, style_codes)\n",
    "#         x = self.residual4(x, style_codes)\n",
    "        x = self.residual5(x, style_codes)\n",
    "\n",
    "        x = self.upsampling1(x, style_codes)\n",
    "        x = self.upsampling2(x, style_codes)\n",
    "\n",
    "        x = self.conv4(x, style_codes)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b584b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_content_loss(features, targets, nodes):\n",
    "    content_loss = 0\n",
    "    for node in nodes:\n",
    "        content_loss += mse_loss(features[node], targets[node])\n",
    "    return content_loss\n",
    "\n",
    "\n",
    "def gram(x):\n",
    "    b, c, h, w = x.size()\n",
    "    f = x.flatten(2)\n",
    "    g = torch.bmm(f, f.transpose(1, 2))\n",
    "    return g.div(h*w)\n",
    "\n",
    "\n",
    "def calc_style_loss(features, targets, nodes):\n",
    "    gram_loss = 0\n",
    "    for node in nodes:\n",
    "        gram_loss += mse_loss(gram(features[node]), gram(targets[node]))\n",
    "    return gram_loss\n",
    "\n",
    "\n",
    "def calc_tv_loss(x):\n",
    "    tv_loss = torch.mean(torch.abs(x[:, :, :, :-1] - x[:, :, :, 1:]))\n",
    "    tv_loss += torch.mean(torch.abs(x[:, :, :-1, :] - x[:, :, 1:, :]))\n",
    "    return tv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d13191",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StyleTransferNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4d7dbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "losses = {'content': [], 'style': [], 'tv': [], 'total': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a829f2fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter.: 100, time taken: 0.28 seconds, content: 13.8616, style: 2.6055, tv: 0.3848, total: 26.8890\n",
      "iter.: 200, time taken: 0.28 seconds, content: 14.5003, style: 2.8403, tv: 0.4104, total: 28.7019\n",
      "iter.: 300, time taken: 0.30 seconds, content: 13.5037, style: 2.5887, tv: 0.3987, total: 26.4471\n",
      "iter.: 400, time taken: 0.29 seconds, content: 15.0221, style: 2.7741, tv: 0.4148, total: 28.8924\n",
      "iter.: 500, time taken: 0.31 seconds, content: 14.2237, style: 2.5694, tv: 0.4073, total: 27.0707\n",
      "iter.: 600, time taken: 0.30 seconds, content: 14.8373, style: 2.5156, tv: 0.4166, total: 27.4153\n",
      "iter.: 700, time taken: 0.29 seconds, content: 13.2620, style: 2.4252, tv: 0.3937, total: 25.3880\n",
      "iter.: 800, time taken: 0.32 seconds, content: 14.0699, style: 2.2461, tv: 0.4120, total: 25.3002\n",
      "iter.: 900, time taken: 0.31 seconds, content: 13.6203, style: 2.2394, tv: 0.4051, total: 24.8170\n",
      "iter.: 1000, time taken: 0.28 seconds, content: 13.4120, style: 2.0773, tv: 0.4007, total: 23.7987\n",
      "iter.: 1100, time taken: 0.29 seconds, content: 14.1630, style: 2.3400, tv: 0.4294, total: 25.8628\n",
      "iter.: 1200, time taken: 0.32 seconds, content: 13.9320, style: 2.0798, tv: 0.4157, total: 24.3311\n",
      "iter.: 1300, time taken: 0.29 seconds, content: 13.0151, style: 2.1106, tv: 0.4188, total: 23.5683\n",
      "iter.: 1400, time taken: 0.31 seconds, content: 13.4137, style: 1.9131, tv: 0.4097, total: 22.9792\n",
      "iter.: 1500, time taken: 0.38 seconds, content: 13.5193, style: 1.8512, tv: 0.4198, total: 22.7753\n",
      "iter.: 1600, time taken: 0.30 seconds, content: 12.8429, style: 1.8332, tv: 0.4096, total: 22.0091\n",
      "iter.: 1700, time taken: 0.32 seconds, content: 12.9478, style: 1.9020, tv: 0.4181, total: 22.4578\n",
      "iter.: 1800, time taken: 0.30 seconds, content: 13.6600, style: 1.7915, tv: 0.4224, total: 22.6178\n",
      "iter.: 1900, time taken: 0.34 seconds, content: 12.6476, style: 1.7515, tv: 0.4292, total: 21.4052\n",
      "iter.: 2000, time taken: 0.30 seconds, content: 12.5262, style: 1.6572, tv: 0.4100, total: 20.8123\n",
      "iter.: 2100, time taken: 0.31 seconds, content: 12.6280, style: 1.7233, tv: 0.4300, total: 21.2444\n",
      "iter.: 2200, time taken: 0.31 seconds, content: 12.5092, style: 1.6419, tv: 0.4313, total: 20.7188\n",
      "iter.: 2300, time taken: 0.29 seconds, content: 13.0868, style: 1.7719, tv: 0.4156, total: 21.9461\n",
      "iter.: 2400, time taken: 0.30 seconds, content: 13.2283, style: 1.5983, tv: 0.4225, total: 21.2199\n",
      "iter.: 2500, time taken: 0.33 seconds, content: 12.9836, style: 1.7232, tv: 0.4387, total: 21.5997\n",
      "iter.: 2600, time taken: 0.30 seconds, content: 12.2133, style: 1.6449, tv: 0.4155, total: 20.4379\n",
      "iter.: 2700, time taken: 0.29 seconds, content: 12.6175, style: 1.5922, tv: 0.4387, total: 20.5783\n",
      "iter.: 2800, time taken: 0.30 seconds, content: 12.1718, style: 1.5530, tv: 0.4418, total: 19.9370\n",
      "iter.: 2900, time taken: 0.30 seconds, content: 12.3797, style: 1.6240, tv: 0.4131, total: 20.4995\n",
      "iter.: 3000, time taken: 0.31 seconds, content: 13.1043, style: 1.5716, tv: 0.4377, total: 20.9625\n",
      "iter.: 3100, time taken: 0.29 seconds, content: 12.7065, style: 1.4733, tv: 0.4266, total: 20.0731\n",
      "iter.: 3200, time taken: 0.32 seconds, content: 12.4510, style: 1.4732, tv: 0.4306, total: 19.8171\n",
      "iter.: 3300, time taken: 0.30 seconds, content: 12.1102, style: 1.4682, tv: 0.4319, total: 19.4510\n",
      "iter.: 3400, time taken: 0.30 seconds, content: 12.4518, style: 1.4346, tv: 0.4377, total: 19.6249\n",
      "iter.: 3500, time taken: 0.30 seconds, content: 11.7057, style: 1.5094, tv: 0.4287, total: 19.2529\n",
      "iter.: 3600, time taken: 0.33 seconds, content: 12.9279, style: 1.4061, tv: 0.4466, total: 19.9587\n",
      "iter.: 3700, time taken: 0.35 seconds, content: 12.0796, style: 1.4026, tv: 0.4444, total: 19.0924\n",
      "iter.: 3800, time taken: 0.32 seconds, content: 11.9395, style: 1.3274, tv: 0.4321, total: 18.5763\n",
      "iter.: 3900, time taken: 0.30 seconds, content: 11.6892, style: 1.2774, tv: 0.4258, total: 18.0761\n",
      "iter.: 4000, time taken: 0.35 seconds, content: 11.7620, style: 1.3517, tv: 0.4327, total: 18.5203\n",
      "iter.: 4100, time taken: 0.29 seconds, content: 11.7424, style: 1.3629, tv: 0.4377, total: 18.5569\n",
      "iter.: 4200, time taken: 0.30 seconds, content: 12.5589, style: 1.3788, tv: 0.4404, total: 19.4530\n",
      "iter.: 4300, time taken: 0.31 seconds, content: 11.2345, style: 1.3373, tv: 0.4289, total: 17.9212\n",
      "iter.: 4400, time taken: 0.31 seconds, content: 11.7049, style: 1.3306, tv: 0.4265, total: 18.3579\n",
      "iter.: 4500, time taken: 0.33 seconds, content: 12.0956, style: 1.2760, tv: 0.4465, total: 18.4757\n",
      "iter.: 4600, time taken: 0.31 seconds, content: 11.6400, style: 1.2654, tv: 0.4191, total: 17.9672\n",
      "iter.: 4700, time taken: 0.30 seconds, content: 11.1142, style: 1.3760, tv: 0.4381, total: 17.9941\n",
      "iter.: 4800, time taken: 0.31 seconds, content: 11.3884, style: 1.2820, tv: 0.4295, total: 17.7985\n",
      "iter.: 4900, time taken: 0.34 seconds, content: 11.7020, style: 1.2619, tv: 0.4302, total: 18.0114\n",
      "iter.: 5000, time taken: 0.30 seconds, content: 11.3582, style: 1.2782, tv: 0.4186, total: 17.7493\n",
      "iter.: 5100, time taken: 0.33 seconds, content: 11.1814, style: 1.2509, tv: 0.4410, total: 17.4361\n",
      "iter.: 5200, time taken: 0.30 seconds, content: 11.3920, style: 1.2727, tv: 0.4382, total: 17.7557\n",
      "iter.: 5300, time taken: 0.32 seconds, content: 11.5530, style: 1.3770, tv: 0.4457, total: 18.4382\n",
      "iter.: 5400, time taken: 0.31 seconds, content: 11.5872, style: 1.2291, tv: 0.4396, total: 17.7329\n",
      "iter.: 5500, time taken: 0.29 seconds, content: 11.4409, style: 1.1927, tv: 0.4033, total: 17.4042\n",
      "iter.: 5600, time taken: 0.32 seconds, content: 11.4794, style: 1.1810, tv: 0.4194, total: 17.3846\n",
      "iter.: 5700, time taken: 0.30 seconds, content: 11.2769, style: 1.2647, tv: 0.4497, total: 17.6004\n",
      "iter.: 5800, time taken: 0.33 seconds, content: 11.4389, style: 1.2281, tv: 0.4381, total: 17.5796\n",
      "iter.: 5900, time taken: 0.36 seconds, content: 11.4923, style: 1.1767, tv: 0.4384, total: 17.3756\n",
      "iter.: 6000, time taken: 0.30 seconds, content: 11.2521, style: 1.2092, tv: 0.4377, total: 17.2982\n",
      "iter.: 6100, time taken: 0.29 seconds, content: 10.8838, style: 1.2061, tv: 0.4283, total: 16.9144\n",
      "iter.: 6200, time taken: 0.31 seconds, content: 10.8525, style: 1.2097, tv: 0.4444, total: 16.9010\n",
      "iter.: 6300, time taken: 0.29 seconds, content: 10.8627, style: 1.2059, tv: 0.4417, total: 16.8922\n",
      "iter.: 6400, time taken: 0.29 seconds, content: 11.3410, style: 1.2460, tv: 0.4441, total: 17.5712\n",
      "iter.: 6500, time taken: 0.31 seconds, content: 10.8214, style: 1.1213, tv: 0.4453, total: 16.4279\n",
      "iter.: 6600, time taken: 0.28 seconds, content: 11.2254, style: 1.1894, tv: 0.4529, total: 17.1724\n",
      "iter.: 6700, time taken: 0.32 seconds, content: 10.7110, style: 1.2370, tv: 0.4509, total: 16.8958\n",
      "iter.: 6800, time taken: 0.29 seconds, content: 10.9453, style: 1.1466, tv: 0.4304, total: 16.6781\n",
      "iter.: 6900, time taken: 0.34 seconds, content: 11.1937, style: 1.1955, tv: 0.4303, total: 17.1710\n",
      "iter.: 7000, time taken: 0.29 seconds, content: 11.1676, style: 1.1341, tv: 0.4629, total: 16.8382\n",
      "iter.: 7100, time taken: 0.29 seconds, content: 11.5769, style: 1.1885, tv: 0.4500, total: 17.5195\n",
      "iter.: 7200, time taken: 0.29 seconds, content: 11.2571, style: 1.1986, tv: 0.4408, total: 17.2500\n",
      "iter.: 7300, time taken: 0.35 seconds, content: 10.2607, style: 1.1134, tv: 0.4222, total: 15.8278\n",
      "iter.: 7400, time taken: 0.31 seconds, content: 11.0716, style: 1.1377, tv: 0.4443, total: 16.7599\n",
      "iter.: 7500, time taken: 0.34 seconds, content: 11.1586, style: 1.1346, tv: 0.4180, total: 16.8314\n",
      "iter.: 7600, time taken: 0.30 seconds, content: 10.2285, style: 1.2172, tv: 0.4247, total: 16.3143\n",
      "iter.: 7700, time taken: 0.29 seconds, content: 10.7281, style: 1.1376, tv: 0.4376, total: 16.4160\n",
      "iter.: 7800, time taken: 0.32 seconds, content: 10.4698, style: 1.1000, tv: 0.4285, total: 15.9698\n",
      "iter.: 7900, time taken: 0.31 seconds, content: 10.5658, style: 1.1456, tv: 0.4466, total: 16.2937\n",
      "iter.: 8000, time taken: 0.34 seconds, content: 10.8732, style: 1.1519, tv: 0.4612, total: 16.6327\n",
      "iter.: 8100, time taken: 0.32 seconds, content: 11.2256, style: 1.1015, tv: 0.4504, total: 16.7329\n",
      "iter.: 8200, time taken: 0.32 seconds, content: 10.2465, style: 1.0986, tv: 0.4275, total: 15.7395\n",
      "iter.: 8300, time taken: 0.31 seconds, content: 10.6287, style: 1.1499, tv: 0.4310, total: 16.3781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter.: 8400, time taken: 0.31 seconds, content: 10.7585, style: 1.1577, tv: 0.4299, total: 16.5470\n",
      "iter.: 8500, time taken: 0.33 seconds, content: 10.2867, style: 1.1268, tv: 0.4106, total: 15.9205\n",
      "iter.: 8600, time taken: 0.38 seconds, content: 10.5280, style: 1.0737, tv: 0.4457, total: 15.8967\n",
      "iter.: 8700, time taken: 0.39 seconds, content: 10.5497, style: 1.1165, tv: 0.4415, total: 16.1323\n",
      "iter.: 8800, time taken: 0.33 seconds, content: 10.4605, style: 1.1347, tv: 0.4417, total: 16.1340\n",
      "iter.: 8900, time taken: 0.29 seconds, content: 9.9834, style: 1.1078, tv: 0.4330, total: 15.5224\n",
      "iter.: 9000, time taken: 0.28 seconds, content: 10.6456, style: 1.1477, tv: 0.4524, total: 16.3842\n",
      "iter.: 9100, time taken: 0.32 seconds, content: 10.5545, style: 1.0983, tv: 0.4399, total: 16.0458\n",
      "iter.: 9200, time taken: 0.30 seconds, content: 10.4754, style: 1.0803, tv: 0.4522, total: 15.8768\n",
      "iter.: 9300, time taken: 0.31 seconds, content: 10.3013, style: 1.0841, tv: 0.4221, total: 15.7219\n",
      "iter.: 9400, time taken: 0.32 seconds, content: 10.1316, style: 1.0837, tv: 0.4330, total: 15.5502\n",
      "iter.: 9500, time taken: 0.31 seconds, content: 10.4002, style: 1.1076, tv: 0.4289, total: 15.9384\n",
      "iter.: 9600, time taken: 0.30 seconds, content: 10.2324, style: 1.1188, tv: 0.4573, total: 15.8261\n",
      "iter.: 9700, time taken: 0.29 seconds, content: 9.8879, style: 1.0664, tv: 0.4342, total: 15.2198\n",
      "iter.: 9800, time taken: 0.33 seconds, content: 10.4958, style: 1.0003, tv: 0.4502, total: 15.4970\n",
      "iter.: 9900, time taken: 0.34 seconds, content: 10.5245, style: 1.0957, tv: 0.4275, total: 16.0031\n",
      "iter.: 10000, time taken: 0.30 seconds, content: 10.0814, style: 1.0985, tv: 0.4589, total: 15.5738\n",
      "iter.: 10100, time taken: 0.36 seconds, content: 10.1859, style: 1.0846, tv: 0.4592, total: 15.6090\n",
      "iter.: 10200, time taken: 0.30 seconds, content: 9.9720, style: 1.0628, tv: 0.4375, total: 15.2861\n",
      "iter.: 10300, time taken: 0.30 seconds, content: 10.2515, style: 1.0684, tv: 0.4565, total: 15.5937\n",
      "iter.: 10400, time taken: 0.32 seconds, content: 10.2835, style: 1.0786, tv: 0.4406, total: 15.6766\n",
      "iter.: 10500, time taken: 0.31 seconds, content: 10.2464, style: 1.0944, tv: 0.4396, total: 15.7186\n",
      "iter.: 10600, time taken: 0.36 seconds, content: 10.3014, style: 1.0529, tv: 0.4232, total: 15.5659\n",
      "iter.: 10700, time taken: 0.36 seconds, content: 10.4539, style: 1.0673, tv: 0.4389, total: 15.7903\n",
      "iter.: 10800, time taken: 0.36 seconds, content: 10.2276, style: 1.1367, tv: 0.4411, total: 15.9113\n",
      "iter.: 10900, time taken: 0.35 seconds, content: 10.1425, style: 1.0470, tv: 0.4368, total: 15.3775\n",
      "iter.: 11000, time taken: 0.30 seconds, content: 9.8885, style: 1.0804, tv: 0.4265, total: 15.2907\n",
      "iter.: 11100, time taken: 0.33 seconds, content: 9.7412, style: 1.0576, tv: 0.4339, total: 15.0294\n",
      "iter.: 11200, time taken: 0.32 seconds, content: 9.9831, style: 1.0608, tv: 0.4462, total: 15.2870\n",
      "iter.: 11300, time taken: 0.33 seconds, content: 9.9864, style: 1.0764, tv: 0.4262, total: 15.3683\n",
      "iter.: 11400, time taken: 0.30 seconds, content: 9.5863, style: 0.9937, tv: 0.4338, total: 14.5548\n",
      "iter.: 11500, time taken: 0.33 seconds, content: 9.7746, style: 1.0666, tv: 0.4680, total: 15.1075\n",
      "iter.: 11600, time taken: 0.32 seconds, content: 10.4082, style: 1.1108, tv: 0.4869, total: 15.9621\n",
      "iter.: 11700, time taken: 0.33 seconds, content: 10.1221, style: 0.9618, tv: 0.4401, total: 14.9310\n",
      "iter.: 11800, time taken: 0.30 seconds, content: 9.8796, style: 1.0439, tv: 0.4365, total: 15.0989\n",
      "iter.: 11900, time taken: 0.32 seconds, content: 10.2680, style: 1.1002, tv: 0.4420, total: 15.7689\n",
      "iter.: 12000, time taken: 0.32 seconds, content: 10.0820, style: 1.0433, tv: 0.4637, total: 15.2984\n",
      "iter.: 12100, time taken: 0.33 seconds, content: 10.0336, style: 1.0893, tv: 0.4364, total: 15.4802\n",
      "iter.: 12200, time taken: 0.30 seconds, content: 10.4191, style: 1.0869, tv: 0.4658, total: 15.8536\n",
      "iter.: 12300, time taken: 0.32 seconds, content: 9.8826, style: 1.0768, tv: 0.4535, total: 15.2664\n",
      "iter.: 12400, time taken: 0.31 seconds, content: 9.5845, style: 1.0492, tv: 0.4366, total: 14.8307\n",
      "iter.: 12500, time taken: 0.31 seconds, content: 10.0120, style: 1.0658, tv: 0.4454, total: 15.3412\n",
      "iter.: 12600, time taken: 0.32 seconds, content: 9.3277, style: 1.0387, tv: 0.3981, total: 14.5214\n",
      "iter.: 12700, time taken: 0.29 seconds, content: 9.9780, style: 1.0077, tv: 0.4462, total: 15.0167\n",
      "iter.: 12800, time taken: 0.34 seconds, content: 9.5402, style: 1.0452, tv: 0.4485, total: 14.7661\n",
      "iter.: 12900, time taken: 0.37 seconds, content: 9.4769, style: 1.0355, tv: 0.4452, total: 14.6542\n",
      "iter.: 13000, time taken: 0.31 seconds, content: 10.1297, style: 1.0261, tv: 0.4572, total: 15.2601\n",
      "iter.: 13100, time taken: 0.29 seconds, content: 9.6831, style: 1.0022, tv: 0.4354, total: 14.6943\n",
      "iter.: 13200, time taken: 0.31 seconds, content: 9.8697, style: 1.0586, tv: 0.4624, total: 15.1629\n",
      "iter.: 13300, time taken: 0.36 seconds, content: 9.1520, style: 0.9789, tv: 0.4504, total: 14.0466\n",
      "iter.: 13400, time taken: 0.33 seconds, content: 9.3050, style: 0.9600, tv: 0.4322, total: 14.1052\n",
      "iter.: 13500, time taken: 0.34 seconds, content: 9.5996, style: 0.9810, tv: 0.4579, total: 14.5046\n",
      "iter.: 13600, time taken: 0.30 seconds, content: 9.5766, style: 1.0883, tv: 0.4164, total: 15.0180\n",
      "iter.: 13700, time taken: 0.30 seconds, content: 9.9379, style: 1.0629, tv: 0.4603, total: 15.2526\n",
      "iter.: 13800, time taken: 0.30 seconds, content: 9.2643, style: 1.0760, tv: 0.4410, total: 14.6441\n",
      "iter.: 13900, time taken: 0.31 seconds, content: 9.7090, style: 1.0339, tv: 0.4812, total: 14.8785\n",
      "iter.: 14000, time taken: 0.33 seconds, content: 9.0405, style: 0.9802, tv: 0.4309, total: 13.9415\n",
      "iter.: 14100, time taken: 0.32 seconds, content: 9.9082, style: 1.0371, tv: 0.4469, total: 15.0937\n",
      "iter.: 14200, time taken: 0.35 seconds, content: 9.1470, style: 1.0115, tv: 0.4402, total: 14.2044\n",
      "iter.: 14300, time taken: 0.31 seconds, content: 9.6707, style: 1.0357, tv: 0.4520, total: 14.8492\n",
      "iter.: 14400, time taken: 0.33 seconds, content: 10.2877, style: 1.0196, tv: 0.4815, total: 15.3859\n",
      "iter.: 14500, time taken: 0.31 seconds, content: 9.3851, style: 0.9857, tv: 0.4303, total: 14.3135\n",
      "iter.: 14600, time taken: 0.35 seconds, content: 9.3528, style: 0.9985, tv: 0.4544, total: 14.3452\n",
      "iter.: 14700, time taken: 0.36 seconds, content: 9.1069, style: 1.0025, tv: 0.4529, total: 14.1194\n",
      "iter.: 14800, time taken: 0.33 seconds, content: 9.1012, style: 0.9981, tv: 0.4436, total: 14.0917\n",
      "iter.: 14900, time taken: 0.36 seconds, content: 9.3340, style: 0.9688, tv: 0.4632, total: 14.1779\n",
      "iter.: 15000, time taken: 0.35 seconds, content: 8.6561, style: 1.0037, tv: 0.4362, total: 13.6745\n",
      "iter.: 15100, time taken: 0.34 seconds, content: 9.4428, style: 1.0441, tv: 0.4427, total: 14.6633\n",
      "iter.: 15200, time taken: 0.33 seconds, content: 9.0472, style: 0.9804, tv: 0.4673, total: 13.9491\n",
      "iter.: 15300, time taken: 0.34 seconds, content: 9.1013, style: 0.9943, tv: 0.4643, total: 14.0726\n",
      "iter.: 15400, time taken: 0.33 seconds, content: 8.9553, style: 0.9987, tv: 0.4497, total: 13.9487\n",
      "iter.: 15500, time taken: 0.34 seconds, content: 8.9288, style: 0.9523, tv: 0.4102, total: 13.6902\n",
      "iter.: 15600, time taken: 0.34 seconds, content: 9.7990, style: 1.0208, tv: 0.4642, total: 14.9030\n",
      "iter.: 15700, time taken: 0.31 seconds, content: 8.8506, style: 0.9969, tv: 0.4449, total: 13.8349\n",
      "iter.: 15800, time taken: 0.34 seconds, content: 9.2939, style: 0.9875, tv: 0.4509, total: 14.2314\n",
      "iter.: 15900, time taken: 0.30 seconds, content: 9.5357, style: 0.9749, tv: 0.4409, total: 14.4101\n",
      "iter.: 16000, time taken: 0.33 seconds, content: 8.8784, style: 0.9945, tv: 0.4532, total: 13.8509\n",
      "iter.: 16100, time taken: 0.36 seconds, content: 9.1992, style: 1.0185, tv: 0.4383, total: 14.2916\n",
      "iter.: 16200, time taken: 0.38 seconds, content: 8.8376, style: 1.0125, tv: 0.4507, total: 13.9002\n",
      "iter.: 16300, time taken: 0.30 seconds, content: 9.0721, style: 0.9853, tv: 0.4439, total: 13.9986\n",
      "iter.: 16400, time taken: 0.35 seconds, content: 9.4736, style: 1.0201, tv: 0.4538, total: 14.5743\n",
      "iter.: 16500, time taken: 0.36 seconds, content: 8.6263, style: 1.0255, tv: 0.4477, total: 13.7540\n",
      "iter.: 16600, time taken: 0.34 seconds, content: 9.3474, style: 0.9818, tv: 0.4560, total: 14.2565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter.: 16700, time taken: 0.36 seconds, content: 9.6144, style: 0.9969, tv: 0.4412, total: 14.5989\n",
      "iter.: 16800, time taken: 0.32 seconds, content: 9.2526, style: 1.0186, tv: 0.4429, total: 14.3458\n",
      "iter.: 16900, time taken: 0.36 seconds, content: 9.4632, style: 0.9598, tv: 0.4610, total: 14.2620\n",
      "iter.: 17000, time taken: 0.34 seconds, content: 9.5786, style: 1.0207, tv: 0.4706, total: 14.6819\n",
      "iter.: 17100, time taken: 0.32 seconds, content: 9.1406, style: 0.9854, tv: 0.4339, total: 14.0676\n",
      "iter.: 17200, time taken: 0.33 seconds, content: 9.3071, style: 1.0019, tv: 0.4508, total: 14.3168\n",
      "iter.: 17300, time taken: 0.33 seconds, content: 9.0900, style: 1.0024, tv: 0.4590, total: 14.1019\n",
      "iter.: 17400, time taken: 0.39 seconds, content: 8.9859, style: 0.9571, tv: 0.4416, total: 13.7713\n",
      "iter.: 17500, time taken: 0.34 seconds, content: 8.9581, style: 0.9717, tv: 0.4404, total: 13.8164\n",
      "iter.: 17600, time taken: 0.34 seconds, content: 9.2065, style: 1.0250, tv: 0.4651, total: 14.3316\n",
      "iter.: 17700, time taken: 0.36 seconds, content: 8.7350, style: 1.0058, tv: 0.4306, total: 13.7640\n",
      "iter.: 17800, time taken: 0.33 seconds, content: 8.7518, style: 0.9677, tv: 0.4181, total: 13.5905\n",
      "iter.: 17900, time taken: 0.37 seconds, content: 9.0206, style: 0.9814, tv: 0.4610, total: 13.9276\n",
      "iter.: 18000, time taken: 0.49 seconds, content: 8.4228, style: 0.9396, tv: 0.4279, total: 13.1207\n",
      "iter.: 18100, time taken: 0.37 seconds, content: 8.3238, style: 0.9715, tv: 0.4274, total: 13.1811\n",
      "iter.: 18200, time taken: 0.30 seconds, content: 8.6508, style: 0.9323, tv: 0.4360, total: 13.3123\n",
      "iter.: 18300, time taken: 0.34 seconds, content: 9.3437, style: 0.9795, tv: 0.4570, total: 14.2414\n",
      "iter.: 18400, time taken: 0.34 seconds, content: 8.6295, style: 1.0347, tv: 0.4331, total: 13.8028\n",
      "iter.: 18500, time taken: 0.30 seconds, content: 9.0831, style: 1.0502, tv: 0.4390, total: 14.3339\n",
      "iter.: 18600, time taken: 0.36 seconds, content: 9.1237, style: 0.9392, tv: 0.4635, total: 13.8198\n",
      "iter.: 18700, time taken: 0.34 seconds, content: 8.6838, style: 0.9554, tv: 0.4568, total: 13.4607\n",
      "iter.: 18800, time taken: 0.29 seconds, content: 9.1344, style: 0.9869, tv: 0.4569, total: 14.0687\n",
      "iter.: 18900, time taken: 0.34 seconds, content: 8.5709, style: 0.9623, tv: 0.4393, total: 13.3825\n",
      "iter.: 19000, time taken: 0.32 seconds, content: 8.4886, style: 0.9649, tv: 0.4421, total: 13.3130\n",
      "iter.: 19100, time taken: 0.35 seconds, content: 9.1599, style: 0.9535, tv: 0.4479, total: 13.9272\n",
      "iter.: 19200, time taken: 0.35 seconds, content: 8.9388, style: 0.9542, tv: 0.4405, total: 13.7099\n",
      "iter.: 19300, time taken: 0.32 seconds, content: 8.7451, style: 0.9889, tv: 0.4490, total: 13.6895\n",
      "iter.: 19400, time taken: 0.37 seconds, content: 8.3820, style: 0.9924, tv: 0.4492, total: 13.3443\n",
      "iter.: 19500, time taken: 0.30 seconds, content: 8.5404, style: 0.9641, tv: 0.4452, total: 13.3610\n",
      "iter.: 19600, time taken: 0.35 seconds, content: 8.6430, style: 0.9275, tv: 0.4776, total: 13.2806\n",
      "iter.: 19700, time taken: 0.31 seconds, content: 8.7651, style: 0.9872, tv: 0.4428, total: 13.7013\n",
      "iter.: 19800, time taken: 0.35 seconds, content: 8.8349, style: 0.9872, tv: 0.4429, total: 13.7708\n",
      "iter.: 19900, time taken: 0.33 seconds, content: 8.7274, style: 0.9657, tv: 0.4540, total: 13.5561\n",
      "iter.: 20000, time taken: 0.34 seconds, content: 8.6512, style: 0.9800, tv: 0.4267, total: 13.5513\n",
      "iter.: 20100, time taken: 0.34 seconds, content: 8.7052, style: 0.9733, tv: 0.4517, total: 13.5718\n",
      "iter.: 20200, time taken: 0.35 seconds, content: 8.6474, style: 0.9449, tv: 0.4703, total: 13.3717\n",
      "iter.: 20300, time taken: 0.30 seconds, content: 8.3076, style: 0.9802, tv: 0.4376, total: 13.2086\n",
      "iter.: 20400, time taken: 0.32 seconds, content: 8.4214, style: 0.9630, tv: 0.4561, total: 13.2363\n",
      "iter.: 20500, time taken: 0.36 seconds, content: 8.6815, style: 0.8882, tv: 0.4256, total: 13.1224\n",
      "iter.: 20600, time taken: 0.32 seconds, content: 8.1826, style: 0.9251, tv: 0.4356, total: 12.8081\n",
      "iter.: 20700, time taken: 0.32 seconds, content: 8.3057, style: 0.9377, tv: 0.4552, total: 12.9941\n",
      "iter.: 20800, time taken: 0.33 seconds, content: 8.4843, style: 0.9642, tv: 0.4497, total: 13.3051\n",
      "iter.: 20900, time taken: 0.38 seconds, content: 9.0743, style: 0.9795, tv: 0.4530, total: 13.9717\n",
      "iter.: 21000, time taken: 0.32 seconds, content: 8.5922, style: 0.9191, tv: 0.4572, total: 13.1877\n",
      "iter.: 21100, time taken: 0.34 seconds, content: 8.6719, style: 0.9688, tv: 0.4478, total: 13.5161\n",
      "iter.: 21200, time taken: 0.33 seconds, content: 8.6612, style: 0.9182, tv: 0.4423, total: 13.2523\n",
      "iter.: 21300, time taken: 0.35 seconds, content: 8.9135, style: 0.9140, tv: 0.4366, total: 13.4836\n",
      "iter.: 21400, time taken: 0.34 seconds, content: 8.7440, style: 0.9483, tv: 0.4568, total: 13.4854\n",
      "iter.: 21500, time taken: 0.35 seconds, content: 8.7204, style: 0.9653, tv: 0.4519, total: 13.5469\n",
      "iter.: 21600, time taken: 0.38 seconds, content: 8.1683, style: 0.9286, tv: 0.4491, total: 12.8113\n",
      "iter.: 21700, time taken: 0.37 seconds, content: 8.2932, style: 0.9348, tv: 0.4261, total: 12.9674\n",
      "iter.: 21800, time taken: 0.31 seconds, content: 8.5340, style: 0.9081, tv: 0.4847, total: 13.0748\n",
      "iter.: 21900, time taken: 0.37 seconds, content: 8.2724, style: 0.9226, tv: 0.4214, total: 12.8857\n",
      "iter.: 22000, time taken: 0.35 seconds, content: 8.8515, style: 0.9742, tv: 0.4784, total: 13.7225\n",
      "iter.: 22100, time taken: 0.38 seconds, content: 8.7814, style: 0.9915, tv: 0.4548, total: 13.7391\n",
      "iter.: 22200, time taken: 0.39 seconds, content: 8.4417, style: 0.9395, tv: 0.4508, total: 13.1391\n",
      "iter.: 22300, time taken: 0.30 seconds, content: 8.1323, style: 0.9233, tv: 0.4497, total: 12.7487\n",
      "iter.: 22400, time taken: 0.32 seconds, content: 8.9549, style: 0.9980, tv: 0.4591, total: 13.9451\n",
      "iter.: 22500, time taken: 0.32 seconds, content: 8.6607, style: 0.9376, tv: 0.4569, total: 13.3489\n",
      "iter.: 22600, time taken: 0.36 seconds, content: 8.7975, style: 0.9795, tv: 0.4583, total: 13.6950\n",
      "iter.: 22700, time taken: 0.32 seconds, content: 8.8265, style: 0.9717, tv: 0.4699, total: 13.6852\n",
      "iter.: 22800, time taken: 0.33 seconds, content: 8.7838, style: 0.9629, tv: 0.4653, total: 13.5983\n",
      "iter.: 22900, time taken: 0.33 seconds, content: 8.4295, style: 0.9610, tv: 0.4676, total: 13.2346\n",
      "iter.: 23000, time taken: 0.34 seconds, content: 8.3137, style: 0.9597, tv: 0.4349, total: 13.1122\n",
      "iter.: 23100, time taken: 0.31 seconds, content: 8.3151, style: 0.9776, tv: 0.4367, total: 13.2032\n",
      "iter.: 23200, time taken: 0.32 seconds, content: 8.9976, style: 0.9990, tv: 0.4539, total: 13.9927\n",
      "iter.: 23300, time taken: 0.33 seconds, content: 8.6950, style: 0.9797, tv: 0.4417, total: 13.5937\n",
      "iter.: 23400, time taken: 0.31 seconds, content: 8.8229, style: 0.9193, tv: 0.4364, total: 13.4193\n",
      "iter.: 23500, time taken: 0.34 seconds, content: 8.0415, style: 0.9214, tv: 0.4246, total: 12.6486\n",
      "iter.: 23600, time taken: 0.41 seconds, content: 8.6478, style: 0.9901, tv: 0.4453, total: 13.5984\n",
      "iter.: 23700, time taken: 0.36 seconds, content: 8.8437, style: 0.9667, tv: 0.4557, total: 13.6772\n",
      "iter.: 23800, time taken: 0.30 seconds, content: 8.2482, style: 0.9381, tv: 0.4396, total: 12.9386\n",
      "iter.: 23900, time taken: 0.30 seconds, content: 8.4945, style: 0.9935, tv: 0.4578, total: 13.4621\n",
      "iter.: 24000, time taken: 0.30 seconds, content: 8.2517, style: 0.9465, tv: 0.4380, total: 12.9842\n",
      "iter.: 24100, time taken: 0.35 seconds, content: 8.1565, style: 0.8995, tv: 0.4461, total: 12.6539\n",
      "iter.: 24200, time taken: 0.31 seconds, content: 8.3336, style: 0.8736, tv: 0.4448, total: 12.7014\n",
      "iter.: 24300, time taken: 0.33 seconds, content: 8.5527, style: 0.9213, tv: 0.4744, total: 13.1593\n",
      "iter.: 24400, time taken: 0.34 seconds, content: 8.5374, style: 0.9335, tv: 0.4691, total: 13.2047\n",
      "iter.: 24500, time taken: 0.33 seconds, content: 8.6129, style: 0.9484, tv: 0.4694, total: 13.3551\n",
      "iter.: 24600, time taken: 0.37 seconds, content: 8.6008, style: 0.9462, tv: 0.4490, total: 13.3317\n",
      "iter.: 24700, time taken: 0.33 seconds, content: 8.3093, style: 0.9849, tv: 0.4377, total: 13.2338\n",
      "iter.: 24800, time taken: 0.34 seconds, content: 8.2729, style: 0.9037, tv: 0.4389, total: 12.7915\n",
      "iter.: 24900, time taken: 0.33 seconds, content: 8.7586, style: 0.9200, tv: 0.4686, total: 13.3585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter.: 25000, time taken: 0.35 seconds, content: 8.6821, style: 0.9591, tv: 0.4742, total: 13.4778\n",
      "iter.: 25100, time taken: 0.34 seconds, content: 8.2014, style: 0.9461, tv: 0.4321, total: 12.9319\n",
      "iter.: 25200, time taken: 0.35 seconds, content: 8.5525, style: 0.9650, tv: 0.4652, total: 13.3777\n",
      "iter.: 25300, time taken: 0.36 seconds, content: 8.5831, style: 0.9301, tv: 0.4595, total: 13.2336\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m total_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 40\u001b[0m losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(content_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     41\u001b[0m losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(style_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     42\u001b[0m losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtv\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(tv_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(1, 1+iterations):\n",
    "    start_time = time.time()\n",
    "\n",
    "    content_images, _ = next(iter(content_dataloader))\n",
    "    style_images, style_indices = next(iter(style_dataloader))\n",
    "\n",
    "    style_codes = torch.zeros(batch_size, NUM_STYLE, 1)\n",
    "\n",
    "    for b, s in enumerate(style_indices):\n",
    "        style_codes[b, s] = 1\n",
    "\n",
    "    content_images = content_images.to(device).contiguous()\n",
    "    style_images = style_images.to(device).contiguous()\n",
    "    style_codes = style_codes.to(device).contiguous()\n",
    "\n",
    "    output_images = model(content_images, style_codes)\n",
    "\n",
    "    content_features = loss_network(content_images)\n",
    "    style_features = loss_network(style_images)\n",
    "    output_features = loss_network(output_images)\n",
    "\n",
    "    style_loss = calc_style_loss(output_features,\n",
    "                                 style_features,\n",
    "                                 style_nodes)\n",
    "    content_loss = calc_content_loss(output_features,\n",
    "                                     content_features,\n",
    "                                     content_nodes)\n",
    "    tv_loss = calc_tv_loss(output_images)\n",
    "\n",
    "    total_loss = content_loss \\\n",
    "        + style_loss * style_weight \\\n",
    "        + tv_loss * tv_weight\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses['content'].append(content_loss.item())\n",
    "    losses['style'].append(style_loss.item())\n",
    "    losses['tv'].append(tv_loss.item())\n",
    "    losses['total'].append(total_loss.item())\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        log = f\"iter.: {i}, time taken: {time_taken:.2f} seconds\"\n",
    "        for k, v in losses.items():\n",
    "            # calculate a recent average value\n",
    "            avg = sum(v[-50:]) / 50\n",
    "            log += f\", {k}: {avg:1.4f}\"\n",
    "        print(log)\n",
    "\n",
    "    if i % 5000 == 0:\n",
    "        torch.save({\"state_dict\": model.state_dict()}, f\"model_{i}.ckpt\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "torch.save({\"state_dict\": model.state_dict()}, \"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b9d7e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = torch.load('trained_models/model_25000.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74e3d73d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StyleTransferNetwork(\n",
       "  (conv1): ConvWithCIN(\n",
       "    (padding): ReflectionPad2d((4, 4, 4, 4))\n",
       "    (conv): Conv2d(3, 32, kernel_size=(9, 9), stride=(1, 1))\n",
       "    (cin): CIN(\n",
       "      (normalize): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (conv2): ConvWithCIN(\n",
       "    (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (cin): CIN(\n",
       "      (normalize): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (conv3): ConvWithCIN(\n",
       "    (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (cin): CIN(\n",
       "      (normalize): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (residual1): ResidualBlock(\n",
       "    (conv1): ConvWithCIN(\n",
       "      (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (cin): CIN(\n",
       "        (normalize): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (conv2): ConvWithCIN(\n",
       "      (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (cin): CIN(\n",
       "        (normalize): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (residual3): ResidualBlock(\n",
       "    (conv1): ConvWithCIN(\n",
       "      (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (cin): CIN(\n",
       "        (normalize): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (conv2): ConvWithCIN(\n",
       "      (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (cin): CIN(\n",
       "        (normalize): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (residual5): ResidualBlock(\n",
       "    (conv1): ConvWithCIN(\n",
       "      (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (cin): CIN(\n",
       "        (normalize): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (conv2): ConvWithCIN(\n",
       "      (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (cin): CIN(\n",
       "        (normalize): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsampling1): UpsamleBlock(\n",
       "    (conv): ConvWithCIN(\n",
       "      (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (cin): CIN(\n",
       "        (normalize): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "  )\n",
       "  (upsampling2): UpsamleBlock(\n",
       "    (conv): ConvWithCIN(\n",
       "      (padding): ReflectionPad2d((1, 1, 1, 1))\n",
       "      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (cin): CIN(\n",
       "        (normalize): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
       "  )\n",
       "  (conv4): ConvWithCIN(\n",
       "    (padding): ReflectionPad2d((4, 4, 4, 4))\n",
       "    (conv): Conv2d(32, 3, kernel_size=(9, 9), stride=(1, 1))\n",
       "    (cin): CIN(\n",
       "      (normalize): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StyleTransferNetwork()\n",
    "model.load_state_dict(check_point['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "738c7e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = '../Dashtoon Task/AdaIn/dataset/content/train_2.5k/COCO_train2014_000000255419.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c273a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2fb3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imload(path, imsize=None, cropsize=None, cencrop=False):\n",
    "    transformer = get_transforms(imsize=imsize,\n",
    "                                 cropsize=cropsize,\n",
    "                                 cencrop=cencrop)\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    return transformer(image).unsqueeze(0)\n",
    "\n",
    "\n",
    "def imsave(image, save_path):\n",
    "    \"\"\"Save a image.\"\"\"\n",
    "    image = denormalize(torchvision.utils.make_grid(image)).clamp_(0.0, 1.0)\n",
    "    torchvision.utils.save_image(image, save_path)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be6e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = imload(test_image_path, imsize=256)\n",
    "style_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f2bdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = '../Dashtoon Task/AdaIn/dataset/content/train_2.5k/COCO_train2014_000000255419.jpg'\n",
    "\n",
    "\n",
    "content_image = imload(test_image_path, imsize=256)\n",
    "style_index = 0\n",
    "\n",
    "# for all styles\n",
    "if style_index == -1:\n",
    "    style_code = torch.eye(NUM_STYLE).unsqueeze(-1)\n",
    "    content_image = content_image.repeat(NUM_STYLE, 1, 1, 1)\n",
    "\n",
    "# for specific style\n",
    "elif style_index in range(NUM_STYLE):\n",
    "    style_code = torch.zeros(1, NUM_STYLE, 1)\n",
    "    style_code[:, style_index, :] = 1\n",
    "    \n",
    "stylized_image = model(content_image, style_code)\n",
    "imsave(stylized_image, 'stylized_images.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30d0b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "stylized_image = model(content_image, style_code)\n",
    "imsave(stylized_image, 'stylized_images.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44965956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
